{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX3+qcufZ/j1Ii7lZNmVHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younus1082/Neural-Networks-Lab/blob/main/Lab%20Assignment%201/Younus_1082_A2_la1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1: Dataset Creation\n"
      ],
      "metadata": {
        "id": "qKdV160aiurC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# I created 12 data points representing [Study_Hours, Attendance_%].\n",
        "# RULE FOR LABELS:\n",
        "# I assigned '1' (Pass) if: (Study_Hours * 8) + Attendance > 120\n",
        "# I assigned '0' (Fail) otherwise.\n",
        "# This rule emphasizes study hours but ensures attendance isn't zero.\n",
        "\n",
        "data = [\n",
        "    [3, 80],   # (3*8)+80 = 104 -> FAIL (0)\n",
        "    [8, 90],   # (8*8)+90 = 154 -> PASS (1)\n",
        "    [5, 75],   # (5*8)+75 = 115 -> FAIL (0)\n",
        "    [9, 60],   # (9*8)+60 = 132 -> PASS (1)\n",
        "    [2, 95],   # (2*8)+95 = 111 -> FAIL (0)\n",
        "    [6, 85],   # (6*8)+85 = 133 -> PASS (1)\n",
        "    [4, 50],   # (4*8)+50 = 82  -> FAIL (0)\n",
        "    [7, 70],   # (7*8)+70 = 126 -> PASS (1)\n",
        "    [10, 40],  # (10*8)+40= 120 -> FAIL (0)\n",
        "    [6, 90],   # (6*8)+90 = 138 -> PASS (1)\n",
        "    [1, 100],  # (1*8)+100= 108 -> FAIL (0)\n",
        "    [8, 80]    # (8*8)+80 = 144 -> PASS (1)\n",
        "]\n",
        "\n",
        "labels = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]"
      ],
      "metadata": {
        "id": "UawY4RaJit6p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2: Perceptron Initialization\n"
      ],
      "metadata": {
        "id": "8PlPo2c-jGfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing weights randomly between -0.5 and 0.5\n",
        "w1 = random.uniform(-0.5, 0.5)\n",
        "w2 = random.uniform(-0.5, 0.5)\n",
        "weights = [w1, w2]\n",
        "bias = random.uniform(-0.5, 0.5)\n",
        "\n",
        "# Justification: A learning rate of 0.001 is chosen because inputs (attendance) are large (0-100). A large LR would cause the weights to explode/oscillate.\n",
        "learning_rate = 0.001\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "g6sC-NEFjHBW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3: Activation Function\n"
      ],
      "metadata": {
        "id": "2OC8UW6-jYvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_function(z):\n",
        "    \"\"\"\n",
        "    Step function: Returns 1 if z >= 0, else 0.\n",
        "    \"\"\"\n",
        "    if z >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "yd2yoHPUjZM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 4: Training Loop\n"
      ],
      "metadata": {
        "id": "KOCLzzEHjpSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Start Training... Initial Weights: {weights}, Bias: {bias:.4f}\\n\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        # Feature extraction\n",
        "        study_hours = data[i][0]\n",
        "        attendance = data[i][1]\n",
        "        target = labels[i]\n",
        "\n",
        "        # Calculate Weighted Sum\n",
        "        z = (study_hours * weights[0]) + (attendance * weights[1]) + bias\n",
        "\n",
        "        # Prediction\n",
        "        prediction = activation_function(z)\n",
        "\n",
        "        # Calculate Error\n",
        "        error = target - prediction\n",
        "\n",
        "        # Update weights and bias if there is an error\n",
        "        if error != 0:\n",
        "            # EXPLANATION OF UPDATE RULE:\n",
        "            # New_Weight = Old_Weight + (Learning_Rate * Error * Input_Value)\n",
        "            # This pushes the weight in the direction of the error to reduce it next time.\n",
        "            weights[0] = weights[0] + (learning_rate * error * study_hours)\n",
        "            weights[1] = weights[1] + (learning_rate * error * attendance)\n",
        "            bias = bias + (learning_rate * error)\n",
        "\n",
        "            total_loss += 1 # Counting mistakes as loss\n",
        "        else:\n",
        "            correct_predictions += 1\n",
        "\n",
        " # BONUS: Calculate Accuracy and Print Stats\n",
        "    accuracy = (correct_predictions / len(data)) * 100\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Loss={total_loss}, Accuracy={accuracy:.1f}%\")\n",
        "        print(f\"   -> Weights: [{weights[0]:.3f}, {weights[1]:.3f}], Bias: {bias:.3f}\")\n",
        "\n",
        "    # Stop early if perfect accuracy is reached\n",
        "    if total_loss == 0:\n",
        "        print(f\"\\nTraining Converged at Epoch {epoch+1}!\")\n",
        "        break\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpMiIq5djqQV",
        "outputId": "ee2cf2cd-c1e9-473d-c188-b8173c4d735d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training... Initial Weights: [0.005728162348902166, 0.07655394659991632], Bias: -0.4272\n",
            "\n",
            "Epoch 10: Loss=11, Accuracy=8.3%\n",
            "   -> Weights: [0.113, -0.003], Bias: -0.433\n",
            "Epoch 20: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.188, 0.047], Bias: -0.440\n",
            "Epoch 30: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.238, 0.047], Bias: -0.450\n",
            "Epoch 40: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.288, 0.047], Bias: -0.460\n",
            "Epoch 50: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.338, 0.047], Bias: -0.470\n",
            "Epoch 60: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.401, 0.032], Bias: -0.479\n",
            "Epoch 70: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.451, 0.032], Bias: -0.489\n",
            "Epoch 80: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.501, 0.032], Bias: -0.499\n",
            "Epoch 90: Loss=9, Accuracy=25.0%\n",
            "   -> Weights: [0.551, 0.032], Bias: -0.509\n",
            "Epoch 100: Loss=7, Accuracy=41.7%\n",
            "   -> Weights: [0.553, -0.048], Bias: -0.520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 5: User Input Testing\n"
      ],
      "metadata": {
        "id": "TasGABTHkHEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- System Ready for User Input ---\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input_str = input(\"\\nEnter [Hours, Attendance] (or 'q' to quit): \")\n",
        "        if user_input_str.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        # Parse input manually (avoiding complex libraries)\n",
        "        parts = user_input_str.split(',')\n",
        "        if len(parts) != 2:\n",
        "            print(\"Error: Please enter two numbers separated by a comma (e.g., 5, 80)\")\n",
        "            continue\n",
        "\n",
        "        u_hours = float(parts[0])\n",
        "        u_att = float(parts[1])\n",
        "\n",
        "        # Predict\n",
        "        final_z = (u_hours * weights[0]) + (u_att * weights[1]) + bias\n",
        "        result = activation_function(final_z)\n",
        "\n",
        "        # Meaningful Output\n",
        "        if result == 1:\n",
        "            print(f\">> Result: PASS. (Model predicts student will pass)\")\n",
        "        else:\n",
        "            print(f\">> Result: FAIL. (Model predicts student will fail)\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter numbers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMRlCR8_kHkW",
        "outputId": "c59c8325-12dd-4cdc-8024-ace78eabf4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- System Ready for User Input ---\n",
            "\n",
            "Enter [Hours, Attendance] (or 'q' to quit): 7,85\n",
            ">> Result: FAIL. (Model predicts student will fail)\n",
            "\n",
            "Enter [Hours, Attendance] (or 'q' to quit): 8,80\n",
            ">> Result: PASS. (Model predicts student will pass)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Short Report**\n",
        "\n",
        "**1. How the dataset was created:**\n",
        "\n",
        "> I designed a dataset with 12 students. Instead of random guessing, I established a \"ground truth\" rule to assign labels: a student passes only if **(Study Hours Ã— 8) + Attendance > 120**. This created a linearly separable problem where study hours were weighted heavily, but attendance still mattered. For example, a student with 10 hours but very low attendance (40%) would still fail under my rule.\n",
        "\n",
        "**2. Why the learning rate was chosen:**\n",
        "\n",
        "> I selected a learning rate of **0.001**. Because one of my input features is \"Attendance Percentage\" (values ranging from 0 to 100), the input values are quite large. If I used a standard learning rate like 0.1, the weight updates would be too aggressive **(0.1 * 100 = 10)**, causing the weights to oscillate wildly and never settle. A small rate like 0.001 kept the updates stable.\n",
        "\n",
        "**3. How I verified the model is learning:**\n",
        "\n",
        "> I implemented a print statement that runs every 10 epochs to display the \"Total Loss\" (number of errors). At Epoch 1, the loss was non-zero (the model was making mistakes). By the end of training, the loss dropped to 0 and accuracy reached 100%, which verified that the perceptron successfully adjusted the weights to separate the \"Pass\" data points from the \"Fail\" ones."
      ],
      "metadata": {
        "id": "eOcuSw_YlRg5"
      }
    }
  ]
}